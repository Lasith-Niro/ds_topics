{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypothesis Test\n",
    "\n",
    "1) Hypothesis Testing Framework\n",
    "* Criteria for conducting Hypothesis testing:\n",
    "    * Interested in comparison of some population parameters that you don't have access to (but you can collect sample data)\n",
    "    * Have competing hypothesis to test using the sample data\n",
    "        * Example: \n",
    "            * $H_0$ (Null): men and women make the same amount of money\n",
    "            * $H_A$ (Alternative): men make more money than women\n",
    "* Setup: **innocent ($H_0$) until proven guilty ($H_A$)**\n",
    "    * Assume null hypothesis is true and look for evidence to the contrary\n",
    "* Hypothesis testing **doesn't** allow for causation, only inference based on evidence or lack thereof\n",
    "    * Conclusions to draw:\n",
    "        * There is **sufficient evidence** that John Smith is guilty of murder\n",
    "        * There is **sufficient evidence to reject the null hypothesis** that men and women make the same amount of money\n",
    "    * Conclusion you **can't** draw:\n",
    "        * John Smith is innocent of murder\n",
    "        * Men and women make the same amount of money\n",
    "* Tests: Two-sample comparison of means, One-sample proportion test, Two-sample comparison of proportion, etc.\n",
    "* Steps:\n",
    "    1. State the null hypothesis ($H_0$) and the alternative hypothesis ($H_A$)\n",
    "    2. Choose a significance level, $\\alpha$ (typically $\\alpha=0.05$)\n",
    "    3. Select statistical test, and compute appropriate **test statistic**\n",
    "        * Often test statistic is a sample mean (or difference of two sample means), so we compare it to the t-distribution via CLT\n",
    "    4. Compute **p-value** based on test statistic:\n",
    "        * If p-value < $\\alpha \\Rightarrow$ reject $H_0$ in favor of $H_A$\n",
    "        * If p-value > $\\alpha \\Rightarrow$ fail to reject $H_0$\n",
    "* Hypothesis Test example:\n",
    "* $n=30$, Sample mean: $\\bar{x}=102$, Sample standard deviation: $s=7$\n",
    "    1. $H_0: \\mu = 100$ and $H_A: \\mu \\neq 100$\n",
    "    2. $\\alpha = 0.05$\n",
    "    3. $t = \\frac{\\bar{x}-\\mu_0}{\\frac{s}{\\sqrt{n}}}$ where $s=\\sqrt{\\frac{1}{n-1}\\sum_{i=1}^n (x_i-\\bar{x})^2}$\n",
    "        * $t = \\frac{102-100}{\\frac{7}{\\sqrt{30}}} = 1.565$\n",
    "    4. Since we are doing a two-sided test, we take area to the left of $t=-1.565$ and right of $t=+1.565$\n",
    "        * computed p-value based on $t$: p-value $\\approx$ 0.1284 > 0.05 $\\Rightarrow$ failed to reject null $H_0$\n",
    "* $n=\\textbf{100}$, sample mean: $\\bar{x}=102$, sample standard deviation: $s=7$\n",
    "    1. $H_0: \\mu = 100$ and $H_A: \\mu \\neq 100$\n",
    "    2. $\\alpha = 0.05$\n",
    "    3. $t = \\frac{\\bar{x}-\\mu_0}{\\frac{s}{\\sqrt{n}}}$ where $s=\\sqrt{\\frac{1}{n-1}\\sum_{i=1}^n (x_i-\\bar{x})^2}$\n",
    "        * $t = \\frac{102-100}{\\frac{7}{\\sqrt{\\textbf{100}}}} = \\textbf{2.857}$\n",
    "    4. Since we are doing a two-sided test, we take area to the left of $t=-2.857$ and right of $t=+2.857$\n",
    "        * computed p-value based on $t$: p-value $\\approx$ 0.0052 < 0.05 $\\Rightarrow$ reject null $H_0$ in favor of $H_A$\n",
    "* What is a **t-distribution**? it is essentially a fat-tailed Normal distribution that approaches normal as degrees of freedom $\\rightarrow \\infty$\n",
    "![t_dist](http://ci.columbia.edu/ci/premba_test/c0331/images/s7/6317178747.gif)\n",
    "    * why does the $t = \\frac{\\bar{x}-\\mu_0}{\\frac{s}{\\sqrt{n}}}$ test statistic follow a t-distribution? **Central Limit Theorem (CLT)**\n",
    "* Constructing **Confidence Interval**:\n",
    "    * Example: $n=30$, Sample mean: $\\bar{x}=102$, Sample standard deviation: $s=7$\n",
    "        * CI for $\\mu$ (population mean): $\\begin{align} (\\bar{x}-t_{\\frac{\\alpha}{2}}*\\frac{s}{\\sqrt{n}}, \\bar{x}+t_{\\frac{\\alpha}{2}}*\\frac{s}{\\sqrt{n}}) \n",
    "            & = 102 \\pm 2*\\frac{7}{\\sqrt{30}} \\\\ \n",
    "            & = (99.44, 104.55) \\end{align}$ at $\\alpha = 0.025$\n",
    "        * $qt(0.0975, df=10) = 2.23$\n",
    "        * $qt(0.0975, df=30) = 2.04$\n",
    "        * Appropriate conclusion: With confidence level of 95%, $\\mu$ lies in the interval $(88.28, 115.72)$\n",
    "        * **Not** appropriate conclusion: The probability that true population mean $\\mu$ is in the range $(88.28, 115.72)$ is 95% (This makes a Bayesian inference which is not possible in this case)\n",
    "         ![significance](https://qph.fs.quoracdn.net/main-qimg-334df07d89a6ff234a44eb412b30b5a3)\n",
    "    * All equations necessary to get CI: (example)\n",
    "        * Get sample data, find t-statistic:\n",
    "            * $\\bar{x}=\\frac{x_1+\\dots+x_n}{n}$\n",
    "            * $s=\\sqrt{\\frac{1}{n-1}\\sum_{i=1}^n (x_i-\\bar{x})^2}$\n",
    "                * $\\downarrow$\n",
    "            * $t=\\frac{\\bar{x}-\\mu}{\\frac{s}{\\sqrt{n}}}$\n",
    "        * Setup t-statistic that captures the population mean, $\\mu$, 95% of the time ($c \\approx 2$):\n",
    "            * $P(-c\\leq t \\leq c)=0.95$\n",
    "            * $P(\\bar{x}-\\frac{cs}{\\sqrt{n}}\\leq \\mu \\leq \\bar{x}+\\frac{cs}{\\sqrt{n}})=0.95$\n",
    "            * $(\\bar{x}-\\frac{cs}{\\sqrt{n}},\\bar{x}+\\frac{cs}{\\sqrt{n}})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Type I and Type II Errors\n",
    "* **p-value** - the probability of observing the data we observed (or more extreme) given the null hypothesis is true\n",
    "    ![pvalue](https://qph.fs.quoracdn.net/main-qimg-a084ff8350103a67f1f0409551adb6ef.webp)\n",
    "* **Type I error** - $P($reject $H_0$ $\\big|$ $H_0$ is true$)$ - knowing that the $H_0$ is true, we reject the null\n",
    "* **Type II error** - $P($accept $H_0$ $\\big|$ $H_0$ is false$)$ - knowing that the $H_0$ is false, we accept the null\n",
    "* **Example of Type I vs Type II error:**\n",
    "    * Suppose the null hypothesis, $H_0$, is: The victim of an automobile accident is alive when he arrives at the emergency room of a hospital.\n",
    "        * **Type I error:** The emergency crew thinks that the victim is dead when, in fact, the victim is alive.\n",
    "        * **Type II error:** The emergency crew does not know if the victim is alive when, in fact, the victim is dead.\n",
    "    * Suppose the null hypothesis, H0, is: the blood cultures contain no traces of pathogen X.\n",
    "        * **Type I error:** The researcher thinks the blood cultures do contain traces of pathogen X, when in fact, they do not.\n",
    "        * **Type II error:** The researcher thinks the blood cultures do not contain traces of pathogen X, when in fact, they do.\n",
    "* look at the tail end(s) of the distribution for the sample mean under the null hypothesis\n",
    "* we can always be wrong due to random variation\n",
    "* at this time, we are accepting the $\\alpha$ at this time\n",
    "* questions to ask:\n",
    "    1. What happens when we increase the sample size?\n",
    "    \n",
    "| Ground truth $\\rightarrow$<br/>$\\downarrow$ Hypothesis Test             | $H_0$ is true                      | $H_0$ is false                    |\n",
    "|--------------:|:----------------------------------:|:---------------------------------:|\n",
    "| Accept $H_0$ | Correct Decision<br/> ($1-\\alpha$) | Type II Error<br/> ($\\beta$)      |\n",
    "| Reject $H_0$ | Type I Error<br/> ($\\alpha$)       | Correct Decision<br/> ($1-\\beta$) |\n",
    "![typei_ii_errors](http://www.avance.ch/newsletter/Avance_on_statistics/errors.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![hypothesis_testing](http://nospray.info/img/8295608.jpg)\n",
    "\n",
    "3) **Two-sample t-test for Comparison of Means**\n",
    "* assumptions:\n",
    "    * population distribution is normal (often not true)\n",
    "        * if population distributions are close to normal and sample $n$-size is large, then CLT will allow for this comparison\n",
    "    * standard deviations are equal (often not true)\n",
    "        * can apply **Welch's t-test**, which works with equal or unequal sample sizes, and unequal variances\n",
    "        * possible variations:\n",
    "            * equal sample sizes, equal variance\n",
    "            * equal or unequal sample sizes, equal variance\n",
    "            * equal or unequal sample sizes, unequal variance\n",
    "* hypothesis test example:\n",
    "* $n_1=20, n_2=30$, sample mean: $\\bar{x_1}=101,\\bar{x_2}=95$, sample standard deviation: $s_1=7,s_2=5$\n",
    "    1. $H_0: \\mu_1 = \\mu_2$ and $H_A: \\mu_1 \\gt \\mu_2$\n",
    "    2. $\\alpha = 0.05$\n",
    "    3. $t = \\frac{\\bar{x}_1-\\bar{x}_2}{s_{\\bar{x}_1-\\bar{x}_2}}$ where $s_{\\bar{x}_1-\\bar{x}_2}=\\sqrt{\\frac{s_1^2}{n_1}+\\frac{s_2^2}{n_2}}$\n",
    "        * $t = \\frac{101-95}{\\sqrt{\\frac{49}{20}+\\frac{25}{30}}} = 3.311$\n",
    "    4. since we are doing a one-sided test, we take area to the right of $t=+3.311$\n",
    "        * computed p-value based on $t$: p-value $\\approx$ 0.00116 < 0.05 $\\Rightarrow$ reject null $H_0$ in favor of $H_A$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) **Two-sample z-test for Comparison of Proportions**\n",
    "* this hypothesis testing for proportions isn't much different from comparisons of means\n",
    "    * we are still averaging $x_1,x_2,\\dots,x_n$ except instead of taking on any values, they only take 0 or 1\n",
    "    * means: $X$~$?(\\mu,\\sigma^2)$ $\\rightarrow$(by CLT) $\\rightarrow$ $\\bar{X}$~$Normal(\\mu,\\frac{\\sigma^2}{n})$\n",
    "    * proportions: $X$~$Bernoulli(p)$ $\\rightarrow$(by CLT) $\\rightarrow$ $\\bar{X}$~$Normal(p,\\frac{p(1-p)}{n})$\n",
    "* why are we estimating $z$?\n",
    "    * t-test was used due to estimating $\\sigma$ with sample standard deviation, $s$\n",
    "    * in this case, we just have a single parameter, $p$, not $(\\mu,\\sigma)$\n",
    "* hypothesis test example:\n",
    "* $n_1=300, n_2=1000$, sample proportion: $\\hat{p}_1=0.05,\\hat{p}_2=0.03$\n",
    "    1. $H_0: \\hat{p}_1 = \\hat{p}_2$ and $H_A: \\hat{p}_1 \\gt \\hat{p}_2$\n",
    "    2. $\\alpha = 0.05$\n",
    "    3. $z = \\frac{\\hat{p}_1-\\hat{p}_2-0}{\\sqrt{\\frac{\\hat{p}_1(1-\\hat{p}_1)}{n_1}+\\frac{\\hat{p}_2(1-\\hat{p}_2)}{n_2}}} = \\frac{0.05-0.03}{\\sqrt{\\frac{0.05*0.95}{300}+\\frac{0.03*0.97}{1000}}} = 1.46$\n",
    "    4. since we are doing a one-sided test, we take area to the right of $z=+1.46$\n",
    "        * computed p-value based on $t$: p-value $\\approx$ 0.072 > 0.05 $\\Rightarrow$ fail to reject null $H_0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Multiple Comparisons Problem\n",
    "* Running a hypothesis test and setting $\\alpha=0.05$\n",
    "    * 1st time we run a test, 5% chance of getting Type I error (with 95% chance of **not** getting a false positive)\n",
    "    * 2nd time we run a test, additional 5% chance of Type I error (probability of no Type I error for both tests at $0.95^2 = 0.9025$)\n",
    "    * after $n$ tests, probability of no Type I error for any of $n$ tests is $$0.95^n$$\n",
    "* Example: we want to try 100 variations of original layout of website with small tweaks such as magenta button color, panda icon, etc.\n",
    "    * even if all changes made no difference, expect ~5 variation to be \"successful\"\n",
    "    * there are various methods to counteract multiple comparisons problem:\n",
    "        1. **Bonferroni adjustment**\n",
    "        2. Fisher's least-significant-difference\n",
    "        3. Duncan's test\n",
    "        4. Scheffe's test\n",
    "        5. Tukey's test\n",
    "        6. Dunnett's test\n",
    "* **Bonferroni correction**\n",
    "    * hypotheses $H_1,\\dots,H_m$ with corresponding p-values $p_1,\\dots,p_m$\n",
    "        * $m$ is the total # of null hypotheses\n",
    "        * $m_0$ is the number of true null hypotheses\n",
    "    * **Boole's inequality (aka union bound)** applies here saying that for any finite set of events, the probability that at least one of the events happens is no greater than the sum of probabilities of the individual events\n",
    "        * for set of events: $A_1,A_2,A_3,\\dots,A_n$\n",
    "        * $P(\\bigcup_i A_i) \\leq \\sum_i P(A_i)$\n",
    "    * **Familywise error rate (FWER)** - the probability of rejecting at least one true $H_i$ of making at least one Type I error\n",
    "        * $FWER = P\\Big\\{\\bigcup_{i=1}^{m_0}\\big(p_i \\leq \\frac{\\alpha}{m}\\big) \\Big\\} \\leq \\sum_{i=1}^{m_0} \\big\\{ P\\big(p_i \\leq \\frac{\\alpha}{m}\\big)\\big\\} = m_0 \\frac{\\alpha}{m} \\leq m \\frac{\\alpha}{m} = \\alpha$\n",
    "        * this doesn't require any assumptions about dependence among the p-values or about how many of the null hypotheses are true\n",
    "    * Use for p-values: $$\\frac{\\alpha}{m}$$ instead of $\\alpha$ when we examine the resulting p-values, $p_1,\\dots,p_m$\n",
    "    * Example: testing 10 hypotheses, $m=10$ where $A_1,A_2,A_3,\\dots,A_{10}$\n",
    "        * if $\\alpha=0.05$, we want the overall Type I error to be bounded by 5%\n",
    "        * in worst case scenario, our tests are independent (having nothing to do with each other)\n",
    "        * it's conservative to measure each hypothesis against an **adjusted significance level**, $$\\frac{0.05}{10}=0.005$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Chi-square Test (related to Comparison of Proportions)\n",
    "* this test is a general method for comparing fact with theory\n",
    "* this approach assumes **sampled units fall randomly into cells**, and that the chance of a unit falling into particular cell can be estimated from the theory we're testing (not unlike $H_0$)\n",
    "    * assume a hypothesis ($H_0$), collect some data, and see if test statistic leads one to want to reject that assumption\n",
    "    * example: is there a relationship between age and investment preference?\n",
    "        * $\\chi^2 = \\sum \\frac{(observed-expected)^2}{expected}$\n",
    "\n",
    "|           | Stocks | Bonds | Cash |     |\n",
    "|:---------:|:------:|:-----:|:----:|:---:|\n",
    "| Age 25-34 |   30   |   10  |   1  |  41 |\n",
    "| Age 35-44 |   35   |   25  |   2  |  62 |\n",
    "| Age 45-54 |   38   |   35  |   4  |  77 |\n",
    "| Age 55-70 |   22   |   30  |   4  |  56 |\n",
    "|           |   125  |  100  |  11  | **236** |\n",
    "\n",
    "* if $Z_1,\\dots,Z_k$ are independent, standard normal random variables, then the sum of their squares:\n",
    "    * $Q = \\sum_{i=1}^k Z_i^2$\n",
    "    * the sum of their squares is distributed according to the chi-squared distribution with $k$ degrees of freedom:\n",
    "    * $Q$ ~ $\\chi^2(k)$ or $Q$ ~ $\\chi_k^2$\n",
    "![chi_square_dist](https://upload.wikimedia.org/wikipedia/commons/thumb/3/35/Chi-square_pdf.svg/321px-Chi-square_pdf.svg.png)\n",
    "* **Chi-Square Test of Independence** - hypothesis tests where the assumption is that there is no relationship between the variables\n",
    "    1. expected table under assumption of *no relationship between Race of Victim and Death Penalty*\n",
    "    2. compute $\\chi^2$ test statistic\n",
    "        * Yes/White: $\\frac{(130)(59)}{362} = 21.19$\n",
    "        * No/Black: $\\frac{(232)(303)}{362} = 194.19$\n",
    "        * $\\chi^2 = \\frac{(45-21.19)^2}{21.19} + \\cdots + \\frac{(218-194.19)^2}{194.19} = 49.89$\n",
    "    3. p-value = $P(\\chi^2>49.89) = 1.626e-12 < 0.0001 \\rightarrow$ fail to reject null $H_0$\n",
    "\n",
    "| Death Penalty$\\rightarrow$<br/>$\\downarrow$Race of Victim | Yes |  No | Totals |\n",
    "|--------------------------------:|:---:|:---:|:------:|\n",
    "|               White              |  45 |  85 |   **130**  |\n",
    "|               Black              |  14 | 218 |   232  |\n",
    "|              Totals              |  **59** | 303 |   **362**  |\n",
    "\n",
    "| Expected Table      |  Yes  |   No   |\n",
    "|:-----:|:-----:|:------:|\n",
    "| White | 21.19 | 108.81 |\n",
    "| Black | 37.81 | 194.19 |\n",
    "\n",
    "* **Chi-Square Goodness of Fit Test** - hypothesis tests where the assumption is that the data is consistent with the specified distribution\n",
    "    * uses similar methodology as two-sample comparison of proportions tests (specify the proportion of observations at each level of categorical variable)\n",
    "    * example: race and death penalty dataset\n",
    "    * $n_{white}=130, n_{black}=232, \\hat{p}_w=\\frac{45}{130}, \\hat{p}_b=\\frac{14}{232}$\n",
    "        1. hypothesis: $H_0: p_{white} = p_{black}$ and $H_A: p_{white} \\neq p_{black}$\n",
    "            * let $\\alpha=0.05$\n",
    "        2. $Z = \\frac{(\\hat{p}_1 - \\hat{p}_2)-0}{\\sqrt{\\hat{p}(1-\\hat{p})(\\frac{1}{n_1}+\\frac{1}{n_2})}} = 7.063152$\n",
    "        3. since we are doing a two-sided test, we take area to the left of $z = -7.063$ and right of $z = +7.063$\n",
    "        4. compute p-value $\\approx 1.628e-12 \\Rightarrow$ reject null $H_0$ in favor of $H_A$ \n",
    "    * example: testing hypothesis of expected distribution (# of customers) over 6 days from owner is consistent with observed data\n",
    "        * (observed): some actual data on customer flow\n",
    "        * $H_0$: owner's distribution is correct\n",
    "        * $H_A$: owner's distribution is not correct\n",
    "        * $\\chi^2 = \\frac{(30-20)^2}{20} + \\cdots + \\frac{(20-30)^2}{30} = 11.44$\n",
    "        * resulting chi-squared test statistic: $\\chi^2 = 11.44$\n",
    "        * compare test statistic to $\\chi^2$ distribution with $df = 5$\n",
    "        * p-value = $P(\\chi^2>11.44)=0.0433 < 0.05 \\Rightarrow$ reject null, $H_0$, distribution\n",
    "        \n",
    "|     Day    |  M | Tu | W  | Th | F  | S  | Total |\n",
    "|:----------:|:--:|:--:|----|----|----|----|-------|\n",
    "| Expected % | 10 | 10 | 15 | 20 | 30 | 15 | 100   |\n",
    "|  Observed  | 30 | 14 | 34 | 45 | 57 | 20 | 200   |\n",
    "| Expected   | 20 | 20 | 30 | 40 | 60 | 30 | 200   |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Experimental Design For A/B Testing\n",
    "* Experimental vs Observational\n",
    "    * **Experimental** - *apply treatments* to experimental units (e.g. people, animals, land, etc.) and observe effect of treatment\n",
    "        * conclusion: **establishes causality**\n",
    "        * example: randomly assigning homework to students and measuring the performance of the two groups\n",
    "    * **Observational** - observe subjects and measure variables of interest *without assigning treatments* to subjects\n",
    "        * conclusion: **can't establish causality**\n",
    "        * example: students who did and didn't do their homework and their grades\n",
    "* **Experimental Design**\n",
    "    * randomization into groups of equal sizes\n",
    "        * randomly generate number from 0 to 1\n",
    "        * if $\\leq 0.5$, then assigned to do homework group, otherwise don't do homework group\n",
    "    * assume independent observations\n",
    "        * assume the students don't know if the other students have to do homework or not\n",
    "        * otherwise, that knowledge might affect their performance\n",
    "* **Confounding factor** - an extraneous attribute that correlates with the dependent variable (e.g. performance) and the independent variable (e.g. did homework or didn't do homework)\n",
    "    * what are possible confounding factors?\n",
    "        * how hard-working the student is\n",
    "        * more hard-working students might perform better and are more likely to do their homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "8) **A/B Testing**\n",
    "![ab_testing](ab_testing.png)\n",
    "* Overall Explanation:\n",
    "    * The scenario is where you have **two versions of an element** (A and B) and a **metric that defines success**\n",
    "    * To determine which version is **better**, you subject both versions to **experimentation simultaneously**\n",
    "    * In the end, you measure which version was **more successful** and select that version for real-world application\n",
    "* A/B Testing Framework:\n",
    "    1. Hypothesis\n",
    "        * Scenario: If you're testing a button color, why do you think green will be better than blue? Are you randomly testing colors or do you think a certain contrast between the button and background colors will make the buttom more noticeable to customers?\n",
    "        * Creating a **good hypothesis** and planning the test(s) to prove the hypothesis will give your tests **direction and yield actionable insights** that are **less likely to be due to chance**\n",
    "        * Likewise, A/B testing should be **skipped** in situations where you know that an idea **almost certainly will improve your app** and the risks associated with blindly implementing the idea are low\n",
    "        * e.g. Robot Invader consistently asks beta users for feedback. After playing the beta version of their newest game, Wind-up Knight 2, several players thought there wasn't enough congratulatory \"glitter\" after completing achievements\n",
    "            * The recommendation from users was that more celebratory features to be added so that players would feel rewarded after accomplishing certain tasks and be more aware of the new features they just unlocked\n",
    "            * The downsides of implementing something like this are close to zero, and the likely impact is positive\n",
    "            * There is no reason to spend time and resources to test something that probably is good and has low risk, which means jumping to implementation of the new feature is perfectly advisable\n",
    "    2. Test impactful elements first\n",
    "        * After you have a clear idea of what you are testing why, it's important to **choose the elements** you decide to test on **each variant with careful consideration**\n",
    "        * Although, there likely won't be a technical limit to how many variants you can test with most modern AB testing solutions, it can be a **waste of time and resources if you overdo it**\n",
    "        * **Smaller, sequential, AB tests** may seem like they have less power, but they **make the data collection and evaluation much more straight forward**, typically leading to **fewer mistakes**\n",
    "        * Make sure to test the elements of the campaign that will make the **largest difference** in **gaining higher conversions**\n",
    "        * While every little design element can have affect to your conversion rates, it is better to start with running tests on **larger elements** that seem like they will impact the user's decision process **the most**\n",
    "        * e.g. Instead of first running tests for every button's color, shape, and size, consider elements like the **wording in a call-to-action** or the **amount of discount in an virtual goods promotion**\n",
    "    3. Run your test for the full duration\n",
    "        * It can be tempting to set up a A/B test and monitor its performance so closely that you are **collecting inaccurate data**\n",
    "        * **Drawing conclusions too soon** in the testing process can cause you to want to **end the test early**\n",
    "        * This usually manifests when you see an **early \"clear winner\"** or decide out of intuition the test ran long enough based on the amount of data collected\n",
    "        * Evaluating the variants' performance and choosing a winner **before the planned test if fully complete** will drastically **increase** the chance of **choosing the incorrect variant**\n",
    "        * By not allowing your A/B test to run the **entire pre-chosen duration** can , and will, lead you to **incorrect and incomplete conclusions**\n",
    "        * Run tests for **at least a month**. The **longer you run** the test, the **more confidence you can have in the accuracy** of the results\n",
    "    4. Evaluate\n",
    "        * Scenario of Results from A/B Test:\n",
    "            * A - \"Stay Stylish for Autumn\" Landing page bounce rate of 76.8%\n",
    "            * B - \"Get Stylish for Autumn\" Landing page bounce rate of 72.5%\n",
    "        * The B version of the landing page showed an encouraging reduction in bounce rate, which means you can switch the copy to the latter knowing with confidence that it would yield better results\n",
    "        * But, why did you see this positive change? A/B testing is not just about random experiments, it's about **learning what your audience wants and why**\n",
    "        * Look to the data to discover why the users preferred one landing page over another\n",
    "* Best practices:\n",
    "    * Don't run test during seasonal periods where the results may be skewed by natural changes in consumer behavior\n",
    "    * The choice of what to test will obviously depend on your goals\n",
    "        * e.g. Increasing number of sign-ups, then test the following: length of the sign-up form, types of fields in the form, display of privacy policy, \"social proof\", etc.\n",
    "        * The goal of A/B testing in this case is to figure out what prevents visitors from signing up\n",
    "        * e.g. Is the form's length intimidating?\n",
    "    * When doing A/B testing, never ever wait to test the variation until after you've tested the control. Always test both versions simultaneously\n",
    "        * e.g. If you test one version one week and the second the next, then it is possible that version B was actually worse but you just happened to have better sales while testing it\n",
    "        * Always split traffic between two versions\n",
    "    * If you are testing a core part of your website, include only new visitors in the test\n",
    "        * You want to avoid shocking regular visitors, especially because the variations may not ultimately be implemented\n",
    "    * The A/B testing tool should have a mechanism for remembering which variation a visitor has seen\n",
    "        * This prevents blunders such as showing a user a different price or a different promotional offer\n",
    "    * If you are testing a sign-up buton that appears in multiple locations, then a visitor should see the same variation everywhere\n",
    "        * Showing one variation on page 1 and another variation on page 2 will **skew** the results\n",
    "    * Run tests one step at a time (An easy mistake to make)\n",
    "        * e.g. If you're testing the color of your call-to-action button, that's all you should test\n",
    "        * Testing anything else simultaneously, even changing the copy on the button, makes your findings less precise and certain\n",
    "        * Did the color change increase conversions, or the new copy?\n",
    "    * Need to have enough data points to gather statistically significant results\n",
    "        * Need to have minimum number of users participating in each test\n",
    "        * Depending on how the test was structured (how many variants) and what your expected results are (e.g. a small improvement off of an already high conversion rate or a large improvement off a of a low conversion rate), you might need thousands of users to get statistically significant results\n",
    "* Creating a good hypothesis:\n",
    "    * A hypothesis is essentially a change and effect statement e.g. There is evidence that changing [element tested] from [  ] to [  ] will [increase/decrease] [a conversion metric]\n",
    "    * This statement above is only a theory that be proved or disproved\n",
    "    * Remember that it is important that the impact of the change must be measured in quantifiable terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
