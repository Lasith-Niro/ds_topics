{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Neural Networks (CovNet/CNN)\n",
    "\n",
    "* Objectives:\n",
    "    * Understand the fundamental differences between image data and other kinds of data\n",
    "    * Be aware of the tools and pipeline for working with images\n",
    "    * Understand general computer vision techniques for working/transforming images\n",
    "    * Be able to explain what a convolution is, and how it works\n",
    "    * Understand the basic structure of a convolutional neural network\n",
    "    * Comprehend the three basic ideas behind convolutional networks: Local receptive field, shared weights, and pooling\n",
    "    * Be aware of general strategies for building convolutional neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) **Image Processing** - remove unnecessary details to allow for better generalization of images to image classes\n",
    "* equation: $x_i \\rightarrow y_i: argmin_y \\frac{1}{2}\\sum_{i=1}(x_i-y_i)^2+\\lambda\\sum_{i=1}|y_{i+1}-y_i|$\n",
    "    * **Fidelity** - $\\frac{1}{2}\\sum_{i=1}(x_i-y_i)^2$\n",
    "    * **Variation** - $\\lambda\\sum_{i=1}|y_{i+1}-y_i|$\n",
    "* What is the difficulty of image processing?\n",
    "    * Images come in many different sizes\n",
    "    * Viewing conditions are infinite\n",
    "    * Objects are surrounded by other objects\n",
    "    * Computers have hard time understanding the context of an image (e.g. Barack Obama secretly stepping on his staff member's scale as a joke)\n",
    "* Why is it important to understand how to process images? Simply that there is more and more data in the form of audio, image and video that have potential for modeling\n",
    "* How do we make object recognition possible?\n",
    "    * Compress the data\n",
    "    * Keep the search simple\n",
    "    * Method of segmenting potential objects\n",
    "* Python libaries for image processing:\n",
    "    * **Scikit-image (skimage)**\n",
    "    * **OpenCV (based on C++)**\n",
    "        * be careful with package dependencies\n",
    "    * Python Imaging Library\n",
    "    * Pillow\n",
    "* Image Pipeline: Read, Resize, and Transformations\n",
    "    * Reading Images (Image types):\n",
    "        * Colored images shape: (width, height, 3)\n",
    "        * Greyscale images shape: (width, height)\n",
    "        * Image Tensor example: (RGB)\n",
    "        ```python\n",
    "        array([\n",
    "            #  R  G  B     R  G  B \n",
    "            [[108,50,13],[111,55,18]],\n",
    "            #  R  G  B     R  G  B\n",
    "            [[115,61,23],[130,129,127]]\n",
    "        ])\n",
    "        ```\n",
    "        * What is the shape of this array? (2, 2, 3)\n",
    "        * What if the same array is greyscaled? (2, 2)\n",
    "    * Resizing Images:\n",
    "        * Making the image a specified shape without cropping\n",
    "            * **Downsampling** - reducing the size of the image when image is too large for processing\n",
    "            ![downsampling](downsampling.png)\n",
    "            * **Upsampling** - purposely increasing the size of image when image is too small for processing\n",
    "            ![upsampling](upsampling.png)\n",
    "            * **Interpolation** - resize or distort your image from one pixel grid to another\n",
    "            ![interpolation](http://northstar-www.dartmouth.edu/doc/idl/html_6.2/images/Interpolation_Methods-14.jpg)\n",
    "    * Transforming Images - converting an image from one domain to another\n",
    "        * **Greyscale** - removing color from image\n",
    "        * **Denoise** - removing unnecessary details of an image allowing for better generalization of the class of image\n",
    "            * **Gaussian Kernel** - probability density function (called the standard deviation), and the square of it, $s^2$, the variance\n",
    "            ![gaussian_kernel](gaussian_kernel.png)\n",
    "    * Before convolution neural nets, image analysis (or object recognition) was focused on examining pixels (or color vectors)\n",
    "        * **K-means of RGB pixels** - segment colors in an automated fashion using k-means clustering\n",
    "        ![kmeans_of_pixel_colors](https://www.mathworks.com/matlabcentral/answers/uploaded_files/9604/sample.jpg)\n",
    "        * **Raw Vector based methods** - ascertain features in images by looking at intensity gradients\n",
    "        ![raw_vector_method](raw_vector_method.png)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "2) Image Featurization in Covolutional Neural Nets\n",
    "* **Convolutions** - in image processing, a kernel, convolution matrix, or mask is a small matrix useful for blurring, sharpening, embossing, edge-detection, and more. This is accomplished by means of **convolution** between kernel and an image\n",
    "    * Applying a kernel over an image to get a convolved feature:\n",
    "    ![kernel_apply](kernel_apply.png)\n",
    "    * Moving a kernel in an image and getting the dot product of each pixel\n",
    "        * dot product: $a \\cdot b=\\sum_{i=1}^n a_i b_i = a_1 b_1 + a_2 b_2 + \\cdots + a_n b_n$\n",
    "        * $\\left[\\begin{array}{cc}\n",
    "            (1)(1) & (1)(0) & (1)(1) \\\\ \n",
    "            (0)(0) & (1)(1) & (1)(0) \\\\\n",
    "            (0)(1) & (0)(0) & (1)(1)\n",
    "            \\end{array}\\right] = \\left[\\begin{array}{cc}\n",
    "            1 & 0 & 1 \\\\ \n",
    "            0 & 1 & 0 \\\\\n",
    "            0 & 0 & 1\n",
    "            \\end{array}\\right] = \n",
    "            1+0+1+0+1+0+0+0+1 = 4$ \n",
    "        * Convolved feature: $\\left[\\begin{array}{cc}\n",
    "            4 & - & - \\\\\n",
    "            - & - & - \\\\\n",
    "            - & - & - \n",
    "            \\end{array}\\right]$\n",
    "        * **Sobel filter** - kernels that have values that are on the vertical edges and the horizontal edges to detect edges\n",
    "            * Vertical edge detector example:\n",
    "                * $\\left[\\begin{array}{cc}\n",
    "                    -1 & 0 & +1 \\\\ \n",
    "                    -2 & 0 & +2 \\\\\n",
    "                    -1 & 0 & +1\n",
    "                    \\end{array}\\right]$\n",
    "            * Horizontal edge detector example:\n",
    "                * $\\left[\\begin{array}{cc}\n",
    "                    -1 & -2 & -1 \\\\ \n",
    "                    0 & 0 & 0 \\\\\n",
    "                    +1 & +2 & +1\n",
    "                    \\end{array}\\right]$\n",
    "            * Useful for detecting outline of a door image and to recognize the essential features of a door\n",
    "            ![door_detection_with_edge](door_detection_with_edge.png)\n",
    "        * **Canny Filter**\n",
    "    * What if we could get a computer to build it's own kernels, apply those to images, then interpret those results to perform object recognition? Convolution Neural Networks (CNNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Convolutional Neural Network Architecture\n",
    "![cnn](http://www.mdpi.com/entropy/entropy-19-00242/article_deploy/html/images/entropy-19-00242-g001.png)\n",
    "* General Structure:\n",
    "    * There are three key feature that make CNN structure actualy work: local receptive fields, shared weights, and pooling\n",
    "    * Input Layer $\\rightarrow$ Convolutional Layers $\\rightarrow$ Pooling Layers $\\rightarrow$ Fully Connected Layers $\\rightarrow$ Output Layer\n",
    "* Input Layer $\\rightarrow$ Convolutional Layers:\n",
    "    * Using a kernel, the input image is converted to multiple convolved features (learning different features of the image)\n",
    "    * **Local Receptive Fields** - a group of pixels that has variety of sizes defined by the kernel\n",
    "    ![local_receptive_field](local_receptive_field.png)\n",
    "        * The kernel is slid across the entire image\n",
    "        * Multiple kernels are applied to the image, which results in multiple learned kernels per hidden layer (yielding multiple convolutional layers)\n",
    "        * The image is transformed into the set of local receptive fields\n",
    "    * **Shared Weights** - multiple convolutions are learned or used\n",
    "        * These weights within a convolution are shared\n",
    "    ![convolutional_layers](convolutional_layers.png)\n",
    "* Convolutional Layers $\\rightarrow$ Pooling Layers:\n",
    "    * **Pooling Layers** - used immedidately after convolutional layers, and simplifies the information in the output from the convolutional layer (e.g. **Max Pooling**)\n",
    "        * reduces the computational complexity for later layers\n",
    "        * provides a form of translational invariance\n",
    "    ![max_pool](max_pool.png)\n",
    "* Pooling Layers $\\rightarrow$ Fully Connected Layers:\n",
    "    * **Fully Connected Layers** - used to aggregate all of the information that has been learned in the convolutional and pooling layers\n",
    "    * They produce higher order features in standard NN manner\n",
    "* Fully Connected Layers $\\rightarrow$ Output Layer:\n",
    "    * **Output Layer** - produces the probability that the image is of a certain class\n",
    "    * Softmax can be applied to the output layer, $\\eta_k$ where $k=1,\\dots,K$ to estimate the one-versus-all class probabilities of $K$ classes: $\\frac{e^{\\eta_k}}{\\sum_{k'=1}^K e^{\\eta_k}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) CNN Intuition\n",
    "* Denoising is not actually common to use with CNN, but available\n",
    "* New set of image processing techniques for getting more images (e.g. rotate images, flip images, etc.) - making your model more translational invariant\n",
    "* It is **not** too common to use dropout after convolutional layers (instead use it after fully connected layers)\n",
    "* It is common to have multiple convolutional layers in between pooling layers\n",
    "* ReLU activation units are incredibly popular with CNNs\n",
    "* In general, it is best to go off of a research paper in your domain space that uses CNNs. Start off trying to get something working that uses the same structure they did, and go from there.\n",
    "* CNNs are the best at identifying patterns in complex data (e.g. recognizing digits from images)\n",
    "    * Classifier - Test Error Rate\n",
    "    * Large and Deep Convolutional Network - 0.33%\n",
    "    * SVM with degree 9 polynomial kernel - 0.66%\n",
    "    * Gradient boosted stumps on Haar features - 0.87%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
